{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(audio_path):\n",
    "    x, sample_rate = librosa.load(audio_path, res_type=\"kaiser_fast\")\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=100).T, axis=0)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "i = 0\n",
    "directory = \"E:\\\\ML project\\\\codes\\\\data\\\\LJSpeech-1.1\\\\wavs\\\\\"\n",
    "for audio in os.listdir(directory):\n",
    "    audio_path = directory + audio\n",
    "    features[i] = feature_extraction(audio_path)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the matrix array: (13100, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "# Function to create a 10x10 matrix from an array\n",
    "def create_10x10_matrix(array):\n",
    "    if len(array) >= 100:\n",
    "        return array[:100].reshape(10, 10)\n",
    "    else:\n",
    "        return None  # Not enough elements to create a 10x10 matrix\n",
    "\n",
    "\n",
    "# Create a list to store the matrices\n",
    "matrix_list = []\n",
    "\n",
    "# Iterate through the keys and create matrices\n",
    "for key in features:\n",
    "    matrix = create_10x10_matrix(features[key])\n",
    "    if matrix is not None:\n",
    "        matrix_list.append(matrix)\n",
    "\n",
    "# Convert the list of matrices to a NumPy array\n",
    "matrix_array = np.array(matrix_list)\n",
    "\n",
    "# Example: Print the shape of the resulting array\n",
    "print(\"Shape of the matrix array:\", matrix_array.shape)\n",
    "matrix_array[0]\n",
    "np.save(\"mfcc2_data\", matrix_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a 3D NumPy array 'matrix_array' containing your 10x10 matrices\n",
    "# The shape of matrix_array should be (num_matrices, 10, 10)\n",
    "\n",
    "# Reshape to add the channel dimension\n",
    "matrix_array = matrix_array.reshape(matrix_array.shape[0], 10, 10, 1)\n",
    "y = np.load(\"E:\\\\ML project\\\\codes\\\\nlp\\\\cnn_output.npy\")  # normailized\n",
    "y = y.reshape(-1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    matrix_array, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape to add the channel dimension\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], 10, 10, 1)\n",
    "X_val_reshaped = X_val.reshape(X_val.shape[0], 10, 10, 1)\n",
    "\n",
    "\n",
    "# Define a learning rate scheduler function\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * 0.95  # Adjust the multiplier as needed\n",
    "\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=None, input_shape=(10, 10, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=None))\n",
    "model.add(Dense(30, activation=None))\n",
    "\n",
    "# Use the Adam optimizer with the learning rate scheduler\n",
    "optimizer = Adam(learning_rate=0.02)  # Set the initial learning rate\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "# Define the learning rate scheduler callback\n",
    "lr_scheduler_callback = LearningRateScheduler(lr_scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.018999999575316905.\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 4s 3ms/step - loss: 7.0144 - mse: 7.0144 - val_loss: 0.1616 - val_mse: 0.1616 - lr: 0.0190\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.018049999419599772.\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.0654 - val_mse: 0.0654 - lr: 0.0181\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.017147500067949295.\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0766 - mse: 0.0766 - val_loss: 0.0727 - val_mse: 0.0727 - lr: 0.0171\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.016290125064551828.\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0563 - mse: 0.0563 - val_loss: 0.0606 - val_mse: 0.0606 - lr: 0.0163\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.015475618280470371.\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0537 - mse: 0.0537 - val_loss: 0.0520 - val_mse: 0.0520 - lr: 0.0155\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.01470183772034943.\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0491 - val_mse: 0.0491 - lr: 0.0147\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.013966745790094137.\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0459 - val_mse: 0.0459 - lr: 0.0140\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.013268408412113785.\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0450 - val_mse: 0.0450 - lr: 0.0133\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.012604987947270274.\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0467 - mse: 0.0467 - val_loss: 0.0467 - val_mse: 0.0467 - lr: 0.0126\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.011974738771095872.\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0444 - val_mse: 0.0444 - lr: 0.0120\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.011376001965254545.\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0495 - val_mse: 0.0495 - lr: 0.0114\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.010807201778516172.\n",
      "Epoch 12/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0425 - val_mse: 0.0425 - lr: 0.0108\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.010266842087730765.\n",
      "Epoch 13/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0413 - mse: 0.0413 - val_loss: 0.0470 - val_mse: 0.0470 - lr: 0.0103\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.009753500204533338.\n",
      "Epoch 14/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0407 - mse: 0.0407 - val_loss: 0.0402 - val_mse: 0.0402 - lr: 0.0098\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.009265825105831026.\n",
      "Epoch 15/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0398 - mse: 0.0398 - val_loss: 0.0411 - val_mse: 0.0411 - lr: 0.0093\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.008802533894777297.\n",
      "Epoch 16/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0412 - val_mse: 0.0412 - lr: 0.0088\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.008362407376989721.\n",
      "Epoch 17/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0386 - mse: 0.0386 - val_loss: 0.0399 - val_mse: 0.0399 - lr: 0.0084\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.007944287406280637.\n",
      "Epoch 18/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0388 - val_mse: 0.0388 - lr: 0.0079\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.007547073345631361.\n",
      "Epoch 19/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0387 - val_mse: 0.0387 - lr: 0.0075\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0071697198553010814.\n",
      "Epoch 20/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0385 - val_mse: 0.0385 - lr: 0.0072\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.006811233796179294.\n",
      "Epoch 21/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0379 - val_mse: 0.0379 - lr: 0.0068\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.006470672017894685.\n",
      "Epoch 22/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0379 - val_mse: 0.0379 - lr: 0.0065\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.006147138262167572.\n",
      "Epoch 23/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0383 - val_mse: 0.0383 - lr: 0.0061\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.005839781393297016.\n",
      "Epoch 24/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0378 - val_mse: 0.0378 - lr: 0.0058\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.005547792301513255.\n",
      "Epoch 25/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0376 - val_mse: 0.0376 - lr: 0.0055\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.005270402575843036.\n",
      "Epoch 26/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0378 - val_mse: 0.0378 - lr: 0.0053\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.005006882292218506.\n",
      "Epoch 27/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0377 - val_mse: 0.0377 - lr: 0.0050\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.004756538243964314.\n",
      "Epoch 28/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0379 - val_mse: 0.0379 - lr: 0.0048\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.004518711287528276.\n",
      "Epoch 29/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0382 - val_mse: 0.0382 - lr: 0.0045\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.004292775900103151.\n",
      "Epoch 30/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0382 - val_mse: 0.0382 - lr: 0.0043\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.004078137082979083.\n",
      "Epoch 31/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0380 - val_mse: 0.0380 - lr: 0.0041\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0038742303615435956.\n",
      "Epoch 32/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0379 - val_mse: 0.0379 - lr: 0.0039\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0036805189098231494.\n",
      "Epoch 33/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0381 - val_mse: 0.0381 - lr: 0.0037\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.003496492886915803.\n",
      "Epoch 34/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0381 - val_mse: 0.0381 - lr: 0.0035\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0033216683310456573.\n",
      "Epoch 35/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0379 - val_mse: 0.0379 - lr: 0.0033\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.003155584947671741.\n",
      "Epoch 36/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0389 - val_mse: 0.0389 - lr: 0.0032\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.002997805667109787.\n",
      "Epoch 37/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0381 - val_mse: 0.0381 - lr: 0.0030\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0028479153173975643.\n",
      "Epoch 38/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0381 - val_mse: 0.0381 - lr: 0.0028\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0027055195183493196.\n",
      "Epoch 39/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0384 - val_mse: 0.0384 - lr: 0.0027\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0025702435756102203.\n",
      "Epoch 40/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0382 - val_mse: 0.0382 - lr: 0.0026\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0024417313747107984.\n",
      "Epoch 41/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0373 - mse: 0.0373 - val_loss: 0.0376 - val_mse: 0.0376 - lr: 0.0024\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0023196447174996136.\n",
      "Epoch 42/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0377 - val_mse: 0.0377 - lr: 0.0023\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0022036624373868107.\n",
      "Epoch 43/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0377 - val_mse: 0.0377 - lr: 0.0022\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.002093479293398559.\n",
      "Epoch 44/100\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0378 - val_mse: 0.0378 - lr: 0.0021\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.00198880530660972.\n",
      "Epoch 45/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0380 - val_mse: 0.0380 - lr: 0.0020\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0018893650965765118.\n",
      "Epoch 46/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0377 - val_mse: 0.0377 - lr: 0.0019\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0017948968859855085.\n",
      "Epoch 47/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 0.0018\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0017051520582754163.\n",
      "Epoch 48/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 0.0017\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0016198944940697402.\n",
      "Epoch 49/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 0.0016\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.001538899797014892.\n",
      "Epoch 50/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 0.0015\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0014619548514019697.\n",
      "Epoch 51/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 0.0015\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0013888571585994214.\n",
      "Epoch 52/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 0.0014\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.001319414284080267.\n",
      "Epoch 53/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 0.0013\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0012534435256384314.\n",
      "Epoch 54/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 0.0013\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0011907713604159653.\n",
      "Epoch 55/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0371 - val_mse: 0.0371 - lr: 0.0012\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0011312327813357114.\n",
      "Epoch 56/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0371 - val_mse: 0.0371 - lr: 0.0011\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0010746711865067481.\n",
      "Epoch 57/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0361 - mse: 0.0361 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 0.0011\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0010209376050624996.\n",
      "Epoch 58/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 0.0010\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009698906971607357.\n",
      "Epoch 59/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 9.6989e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0009213961457135156.\n",
      "Epoch 60/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 9.2140e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0008753263246035203.\n",
      "Epoch 61/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 8.7533e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0008315600221976637.\n",
      "Epoch 62/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0371 - val_mse: 0.0371 - lr: 8.3156e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0007899819989688694.\n",
      "Epoch 63/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 7.8998e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0007504828769015147.\n",
      "Epoch 64/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0371 - val_mse: 0.0371 - lr: 7.5048e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0007129587524104863.\n",
      "Epoch 65/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 7.1296e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0006773108092602342.\n",
      "Epoch 66/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 6.7731e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0006434452632674947.\n",
      "Epoch 67/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0371 - val_mse: 0.0371 - lr: 6.4345e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.000611272975220345.\n",
      "Epoch 68/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 6.1127e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0005807093402836472.\n",
      "Epoch 69/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 5.8071e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0005516738456208259.\n",
      "Epoch 70/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 5.5167e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0005240901256911456.\n",
      "Epoch 71/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 5.2409e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.000497885630466044.\n",
      "Epoch 72/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 4.9789e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.00047299134894274175.\n",
      "Epoch 73/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 4.7299e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.00044934178149560463.\n",
      "Epoch 74/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 4.4934e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.00042687469103839246.\n",
      "Epoch 75/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 4.2687e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.00040553096478106453.\n",
      "Epoch 76/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 4.0553e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.00038525442068930714.\n",
      "Epoch 77/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0373 - val_mse: 0.0373 - lr: 3.8525e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0003659916968899779.\n",
      "Epoch 78/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0372 - val_mse: 0.0372 - lr: 3.6599e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0003476921134279109.\n",
      "Epoch 79/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 3.4769e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.00033030750637408346.\n",
      "Epoch 80/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 3.3031e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.00031379214487969875.\n",
      "Epoch 81/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 3.1379e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0002981025376357138.\n",
      "Epoch 82/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 2.9810e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.00028319740522420034.\n",
      "Epoch 83/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 2.8320e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.00026903754187515.\n",
      "Epoch 84/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 2.6904e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.00025558567722328007.\n",
      "Epoch 85/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0374 - val_mse: 0.0374 - lr: 2.5559e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.00024280639336211605.\n",
      "Epoch 86/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 2.4281e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.00023066606954671442.\n",
      "Epoch 87/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 2.3067e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.00021913277159910647.\n",
      "Epoch 88/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 2.1913e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.00020817612748942336.\n",
      "Epoch 89/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 2.0818e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.00019776732733589597.\n",
      "Epoch 90/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.9777e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.00018787895751302128.\n",
      "Epoch 91/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.8788e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.00017848501447588204.\n",
      "Epoch 92/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.7849e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.00016956076651695185.\n",
      "Epoch 93/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.6956e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.00016108272611745634.\n",
      "Epoch 94/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.6108e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.00015302859465009532.\n",
      "Epoch 95/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.5303e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.00014537716560880654.\n",
      "Epoch 96/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0376 - val_mse: 0.0376 - lr: 1.4538e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.00013810831078444607.\n",
      "Epoch 97/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.3811e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.00013120289731887168.\n",
      "Epoch 98/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0375 - val_mse: 0.0375 - lr: 1.3120e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.00012464274623198433.\n",
      "Epoch 99/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0376 - val_mse: 0.0376 - lr: 1.2464e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.00011841060477308929.\n",
      "Epoch 100/100\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0376 - val_mse: 0.0376 - lr: 1.1841e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the learning rate scheduler callback\n",
    "history = model.fit(\n",
    "    X_train_reshaped,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_reshaped, y_val),\n",
    "    callbacks=[lr_scheduler_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 1ms/step\n",
      "Mean Squared Error on Validation Set: 0.0376098087706962\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_val_reshaped)\n",
    "\n",
    "# Calculate MSE on validation set\n",
    "mse_val = mean_squared_error(y_val, predictions)\n",
    "print(\"Mean Squared Error on Validation Set:\", mse_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
