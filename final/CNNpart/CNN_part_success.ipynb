{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 10:55:24.152344: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-06 10:55:24.201400: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-06 10:55:24.201434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-06 10:55:24.202545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-06 10:55:24.210168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 10:55:24.940443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import nn\n",
    "from tensorflow.keras.activations import softmax\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense,LayerNormalization ## alternative for nn.linear\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13100, 500, 40)\n"
     ]
    }
   ],
   "source": [
    "# X_data = np.load(\"../../data/data_mfcc.npy\")\n",
    "X_data = np.load(\"../../data/data_40_500.npy\")\n",
    "X_data = np.transpose(X_data, (0, 2, 1))\n",
    "# X_data=X_data[:100]\n",
    "# X_data = np.expand_dims(X_data, axis=-1)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data = np.load(\"../../data/pad_data_5.npy\")\n",
    "type(Y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_self_attention_mask(sequence_length):\n",
    "    mask = np.tril(np.ones((sequence_length,sequence_length)))\n",
    "    mask[mask==0]=-np.inf\n",
    "    mask[mask==1]=0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = create_self_attention_mask(5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_qk += mask\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_qk)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 10:55:25.984085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.013388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.013710: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.016348: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.016659: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.016839: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.086269: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.086550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.086692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-06 10:55:26.086817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2796 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-12-06 10:55:26.175308: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output is\n",
      " tf.Tensor(\n",
      "[[1.         1.         1.        ]\n",
      " [0.99999994 0.99999994 0.99999994]\n",
      " [1.         1.         1.        ]], shape=(3, 3), dtype=float32)\n",
      "attention weights is \n",
      " tf.Tensor(\n",
      "[[1.         0.         0.        ]\n",
      " [0.7603684  0.23963155 0.        ]\n",
      " [0.6133826  0.19330868 0.19330868]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "q=[[1.0,2.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "k=[[1.0,3.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "v=[[1.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "mask_1=create_self_attention_mask(3)\n",
    "test,weights = scaled_dot_product(q,k,v,mask=mask_1)\n",
    "print(\"output is\\n\",test)\n",
    "print(\"attention weights is \\n\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        even_i = tf.range(0, self.d_model, 2, dtype=tf.float32)\n",
    "        denominator = tf.pow(10000.0, even_i / self.d_model)\n",
    "        position = tf.reshape(\n",
    "            tf.range(self.max_sequence_length, dtype=tf.float32),\n",
    "            (1, self.max_sequence_length, 1),\n",
    "        )\n",
    "        even_PE = tf.sin(position / denominator)\n",
    "        odd_PE = tf.cos(position / denominator)\n",
    "        stacked = tf.stack([even_PE, odd_PE], axis=2)\n",
    "        PE = tf.reshape(stacked, (1, self.max_sequence_length, -1))\n",
    "        print(\"postional encoding output shape\",PE.shape)\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, filters=64, kernel_size=3, **kwargs):\n",
    "        super(ConvolutionalLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\", trainable=True)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        self.conv2 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\",trainable=True)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.ReLU()\n",
    "\n",
    "        self.global_avg_pooling = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        conv1_out = self.relu1(self.batch_norm1(self.conv1(inputs), training=training))\n",
    "        conv2_out = self.relu2(self.batch_norm2(self.conv2(conv1_out), training=training))\n",
    "        gap_out = self.global_avg_pooling(conv2_out)\n",
    "        if training:\n",
    "            print(\"CNN output shape is  \", gap_out.shape)\n",
    "        return gap_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, d_model, max_input_length):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.cnn_layer = ConvolutionalLayer(input_shape=(None, 500,40))  # Adjust input shape\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        cnn_output = self.cnn_layer(inputs)\n",
    "        return cnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([Transformer(d_model=20,max_input_length=500),layers.Dense(30)])\n",
    "# model.build(input_shape=(None, 500, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10480, 500, 40)\n",
      "(2620, 500, 40)\n",
      "(10480, 30)\n",
      "(2620, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_data and Y_data are your input features and labels\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (Transformer)   (13100, 64)               20608     \n",
      "                                                                 \n",
      " dense (Dense)               (13100, 30)               1950      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22558 (88.12 KB)\n",
      "Trainable params: 22302 (87.12 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=10)\n",
    "model.compile(optimizer=optim, loss='mean_squared_error',metrics=['mae'])\n",
    "model.build(input_shape=(13100,500,40))  # Replace your_input_shape with the actual input shape\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "CNN output shape is   (None, 64)\n",
      "CNN output shape is   (None, 64)\n",
      "CNN output shape is   (None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 10:55:28.685850: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-06 10:55:28.752816: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-06 10:55:29.267707: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fb4a82e27a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-06 10:55:29.267731: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-12-06 10:55:29.271960: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701840329.342711   10574 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 5s 9ms/step - loss: 730886.3750 - mae: 485.8378 - val_loss: 662778.1250 - val_mae: 503.3202\n",
      "Epoch 2/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653322.1875 - mae: 501.5869 - val_loss: 662669.9375 - val_mae: 506.0793\n",
      "Epoch 3/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653340.9375 - mae: 501.6714 - val_loss: 663028.5625 - val_mae: 510.4291\n",
      "Epoch 4/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653488.1875 - mae: 502.5520 - val_loss: 663291.6250 - val_mae: 500.9262\n",
      "Epoch 5/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653446.7500 - mae: 501.3461 - val_loss: 663269.1250 - val_mae: 512.2100\n",
      "Epoch 6/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653586.2500 - mae: 502.1270 - val_loss: 663103.5000 - val_mae: 503.6278\n",
      "Epoch 7/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653674.0625 - mae: 502.2512 - val_loss: 663349.3125 - val_mae: 507.0335\n",
      "Epoch 8/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653557.9375 - mae: 502.4483 - val_loss: 663236.2500 - val_mae: 500.3588\n",
      "Epoch 9/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653513.8750 - mae: 501.7342 - val_loss: 663015.7500 - val_mae: 505.5493\n",
      "Epoch 10/10\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 653626.0625 - mae: 501.9567 - val_loss: 663318.6875 - val_mae: 498.5509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb49bf1be20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=10,validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 2ms/step\n",
      "prediction  [586.49884   818.633     754.5613    736.9478    735.6455    768.6073\n",
      " 714.1019    682.07367   661.6007    662.4464    610.3579    528.379\n",
      " 501.02264   498.9172    432.16226   336.79993   303.41092   305.64825\n",
      " 234.81598   179.41928   174.61377   130.13762    70.81951    71.278625\n",
      "  36.486122   58.044548   11.78944     1.790735    1.0597305  -4.7081075]\n",
      "actual  [  10   60 3030    3 3160   40  504  208 1091    6 2561   16 2675    3\n",
      " 1656  298  117   86 2949   18   33   18   33    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_val)\n",
    "print(\"prediction \",prediction[0])\n",
    "print(\"actual \",Y_val[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
