{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:04:46.623802: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 18:04:46.800214: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 18:04:46.800288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 18:04:46.824698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 18:04:46.882282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 18:04:47.692646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import nn\n",
    "from tensorflow.keras.activations import softmax\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense,LayerNormalization ## alternative for nn.linear\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13100, 500, 40)\n"
     ]
    }
   ],
   "source": [
    "# X_data = np.load(\"../../data/data_mfcc.npy\")\n",
    "X_data = np.load(\"../../data/data_40_500.npy\")\n",
    "X_data = np.transpose(X_data, (0, 2, 1))\n",
    "# X_data=X_data[:100]\n",
    "# X_data = np.expand_dims(X_data, axis=-1)\n",
    "print(X_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14518\n",
      "(13100, 30)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"../../data/LJSpeech-1.1/metadata.csv\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"ID\", \"Text1\", \"Text2\"],\n",
    ")\n",
    "texts = data[\"Text1\"].to_list()\n",
    "ID = data[\"ID\"].to_list()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "num_classes = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "Y_data = pad_sequences(sequences, padding=\"post\", maxlen=30)\n",
    "# Y_data=Y_data[:100]\n",
    "print(num_classes)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_self_attention_mask(sequence_length):\n",
    "    mask = np.tril(np.ones((sequence_length,sequence_length)))\n",
    "    mask[mask==0]=-np.inf\n",
    "    mask[mask==1]=0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = create_self_attention_mask(5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_qk += mask\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_qk)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:04:49.958350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.070588: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.070768: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.072513: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.072669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.072818: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.138364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.138493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.138584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 18:04:50.138662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2796 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-12-04 18:04:50.308933: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output is\n",
      " tf.Tensor(\n",
      "[[1.         1.         1.        ]\n",
      " [0.99999994 0.99999994 0.99999994]\n",
      " [1.         1.         1.        ]], shape=(3, 3), dtype=float32)\n",
      "attention weights is \n",
      " tf.Tensor(\n",
      "[[1.         0.         0.        ]\n",
      " [0.7603684  0.23963155 0.        ]\n",
      " [0.6133826  0.19330868 0.19330868]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "q=[[1.0,2.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "k=[[1.0,3.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "v=[[1.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "mask_1=create_self_attention_mask(3)\n",
    "test,weights = scaled_dot_product(q,k,v,mask=mask_1)\n",
    "print(\"output is\\n\",test)\n",
    "print(\"attention weights is \\n\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        even_i = tf.range(0, self.d_model, 2, dtype=tf.float32)\n",
    "        denominator = tf.pow(10000.0, even_i / self.d_model)\n",
    "        position = tf.reshape(\n",
    "            tf.range(self.max_sequence_length, dtype=tf.float32),\n",
    "            (1, self.max_sequence_length, 1),\n",
    "        )\n",
    "        even_PE = tf.sin(position / denominator)\n",
    "        odd_PE = tf.cos(position / denominator)\n",
    "        stacked = tf.stack([even_PE, odd_PE], axis=2)\n",
    "        PE = tf.reshape(stacked, (1, self.max_sequence_length, -1))\n",
    "        print(\"postional encoding output shape\",PE.shape)\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, filters=64, kernel_size=3, **kwargs):\n",
    "        super(ConvolutionalLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\", trainable=True)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        self.conv2 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\",trainable=True)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.ReLU()\n",
    "\n",
    "        self.global_avg_pooling = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        conv1_out = self.relu1(self.batch_norm1(self.conv1(inputs), training=training))\n",
    "        conv2_out = self.relu2(self.batch_norm2(self.conv2(conv1_out), training=training))\n",
    "        gap_out = self.global_avg_pooling(conv2_out)\n",
    "        if training:\n",
    "            print(\"CNN output shape is  \", gap_out.shape)\n",
    "        return gap_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, d_model, max_input_length):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.cnn_layer = ConvolutionalLayer(input_shape=(None, 500,40))  # Adjust input shape\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        cnn_output = self.cnn_layer(inputs)\n",
    "        return cnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([Transformer(d_model=20,max_input_length=500),layers.Dense(30)])\n",
    "# model.build(input_shape=(None, 500, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10480, 500, 40)\n",
      "(2620, 500, 40)\n",
      "(10480, 30)\n",
      "(2620, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_data and Y_data are your input features and labels\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (Transformer)   (13100, 64)               20608     \n",
      "                                                                 \n",
      " dense (Dense)               (13100, 30)               1950      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22558 (88.12 KB)\n",
      "Trainable params: 22302 (87.12 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=5)\n",
    "model.compile(optimizer=optim, loss='mean_squared_error',metrics=['mae'])\n",
    "model.build(input_shape=(13100,500,40))  # Replace your_input_shape with the actual input shape\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN output shape is   (None, 64)\n",
      "CNN output shape is   (None, 64)\n",
      "CNN output shape is   (None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:04:53.374550: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-04 18:04:53.529594: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-04 18:04:54.215319: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fb0ac2c53d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-04 18:04:54.215346: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-12-04 18:04:54.224553: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701693294.316071    4774 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 6s 11ms/step - loss: 3291184.0000 - mae: 886.1008 - val_loss: 3288873.7500 - val_mae: 922.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb0b9bd2e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=1,validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 3ms/step\n",
      "prediction  [ 750.16785  1041.0319   1354.0059   1569.097    1295.1432   1371.7994\n",
      "  881.2695   1193.3322   1107.3003   1065.8328   1113.4763    995.64655\n",
      "  908.2389   1191.3553    801.30145   952.7885    814.50995   530.91705\n",
      "  261.3897    335.10663   565.9772    286.17395   182.61465   128.91176\n",
      "  173.74344    62.93481   112.46759   -20.164324  -76.85158    14.321409]\n",
      "actual  [  18    8  655    1 3689   19  247   60 1007   15  269   22  712    1\n",
      " 1137  164   11    4 3652    3   16    3   16    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_val)\n",
    "print(\"prediction \",prediction[0])\n",
    "print(\"actual \",Y_val[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
