{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 08:45:34.773633: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-05 08:45:34.874480: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-05 08:45:34.874561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-05 08:45:34.877091: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-05 08:45:34.897416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-05 08:45:36.647759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import nn\n",
    "from tensorflow.keras.activations import softmax\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense,LayerNormalization ## alternative for nn.linear\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13100, 30, 64)\n",
      "[  72.01083    147.46912    106.03668    131.80023     12.418795\n",
      "  151.86609    118.946655   122.67044    114.2478     125.68599\n",
      "  -29.96453     85.215195    47.004295   -87.80414     68.71507\n",
      "   86.04312    -34.267963    45.795727   160.45639     96.857025\n",
      "  135.44983    -71.43028     38.807117    -7.3336506  167.19531\n",
      " -101.842926     0.           0.           0.           0.       ]\n"
     ]
    }
   ],
   "source": [
    "X_data = np.load(\"../../data/data_64_30.npy\")\n",
    "X_data = np.transpose(X_data, (0, 2, 1))\n",
    "print(X_data.shape)\n",
    "print(X_data[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14518\n",
      "(13100, 30)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"../../data/LJSpeech-1.1/metadata.csv\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    names=[\"ID\", \"Text1\", \"Text2\"],\n",
    ")\n",
    "texts = data[\"Text1\"].to_list()\n",
    "ID = data[\"ID\"].to_list()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "num_classes = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "Y_data = pad_sequences(sequences, padding=\"post\", maxlen=30)\n",
    "# Y_data=Y_data[:100]\n",
    "print(num_classes)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_self_attention_mask(sequence_length):\n",
    "    mask = np.tril(np.ones((sequence_length,sequence_length)))\n",
    "    mask[mask==0]=-np.inf\n",
    "    mask[mask==1]=0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = create_self_attention_mask(5)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_qk = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_qk += mask\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_qk)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output is\n",
      " tf.Tensor(\n",
      "[[1.         1.         1.        ]\n",
      " [0.99999994 0.99999994 0.99999994]\n",
      " [1.         1.         1.        ]], shape=(3, 3), dtype=float32)\n",
      "attention weights is \n",
      " tf.Tensor(\n",
      "[[1.         0.         0.        ]\n",
      " [0.7603684  0.23963155 0.        ]\n",
      " [0.6133826  0.19330868 0.19330868]], shape=(3, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 08:45:41.054280: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-12-05 08:45:41.054336: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: Pc\n",
      "2023-12-05 08:45:41.054350: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: Pc\n",
      "2023-12-05 08:45:41.054551: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.129.3\n",
      "2023-12-05 08:45:41.054578: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2023-12-05 08:45:41.054585: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.129.3\n"
     ]
    }
   ],
   "source": [
    "q=[[1.0,2.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "k=[[1.0,3.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "v=[[1.0,1.0,1.0],[1.0,1.0,1.0],[1.0,1.0,1.0]]\n",
    "mask_1=create_self_attention_mask(3)\n",
    "test,weights = scaled_dot_product(q,k,v,mask=mask_1)\n",
    "print(\"output is\\n\",test)\n",
    "print(\"attention weights is \\n\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        even_i = tf.range(0, self.d_model, 2, dtype=tf.float32)\n",
    "        denominator = tf.pow(10000.0, even_i / self.d_model)\n",
    "        position = tf.reshape(\n",
    "            tf.range(self.max_sequence_length, dtype=tf.float32),\n",
    "            (1, self.max_sequence_length, 1),\n",
    "        )\n",
    "        even_PE = tf.sin(position / denominator)\n",
    "        odd_PE = tf.cos(position / denominator)\n",
    "        stacked = tf.stack([even_PE, odd_PE], axis=2)\n",
    "        PE = tf.reshape(stacked, (1, self.max_sequence_length, -1))\n",
    "        print(\"postional encoding output shape\",PE.shape)\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape, filters=64, kernel_size=3, **kwargs):\n",
    "        super(ConvolutionalLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\", trainable=True)\n",
    "        self.batch_norm1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        self.conv2 = layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, padding=\"same\",trainable=True)\n",
    "        self.batch_norm2 = layers.BatchNormalization()\n",
    "        self.relu2 = layers.ReLU()\n",
    "\n",
    "        self.global_avg_pooling = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    \n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        conv1_out = self.relu1(self.batch_norm1(self.conv1(inputs), training=training))\n",
    "        conv2_out = self.relu2(self.batch_norm2(self.conv2(conv1_out), training=training))\n",
    "        gap_out = self.global_avg_pooling(conv2_out)\n",
    "        if training:\n",
    "            print(\"CNN output shape is  \", conv2_out.shape)\n",
    "        return conv2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, d_model, max_input_length):\n",
    "        super(CNN_model, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.cnn_layer = ConvolutionalLayer(input_shape=(None, 30,64))  # Adjust input shape\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        cnn_output = self.cnn_layer(inputs)\n",
    "        return cnn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([CNN_model(d_model=20,max_input_length=30),layers.Dense(30)])\n",
    "# model.build(input_shape=(None, 500, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10480, 30, 64)\n",
      "(2620, 30, 64)\n",
      "(10480, 30)\n",
      "(2620, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_data and Y_data are your input features and labels\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cnn_model (CNN_model)       (13100, 30, 64)           25216     \n",
      "                                                                 \n",
      " dense (Dense)               (13100, 30, 30)           1950      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27166 (106.12 KB)\n",
      "Trainable params: 26910 (105.12 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=5)\n",
    "model.compile(optimizer=optim, loss='mean_squared_error',metrics=['mae'])\n",
    "model.build(input_shape=(13100,30,64))  # Replace your_input_shape with the actual input shape\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN output shape is   (None, 30, 64)\n",
      "CNN output shape is   (None, 30, 64)\n",
      "CNN output shape is   (None, 30, 64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_5922/4042995237.py\", line 1, in <module>\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [32,30,30] vs. [32,30]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_1982]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/abhi/ML/ML_project/final/CNNpart/CNN_part_success.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abhi/ML/ML_project/final/CNNpart/CNN_part_success.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,Y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(X_val, Y_val))\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/mean_squared_error/BroadcastGradientArgs defined at (most recent call last):\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/traitlets/config/application.py\", line 1077, in launch_instance\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_5922/4042995237.py\", line 1, in <module>\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/home/abhi/anaconda3/envs/test/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nIncompatible shapes: [32,30,30] vs. [32,30]\n\t [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_1982]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=1,validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_val)\n",
    "print(\"prediction \",prediction[0])\n",
    "print(\"actual \",Y_val[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
